{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peoAdSrTDqP2"
   },
   "source": [
    "# <h1 align= 'center'>PyTorch RNN Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for this analysis is to predict if a review rates the movie positively or negatively. Inside this dataset, there are 25,000 labelled movies reviews for training, 50,000 unlabeled reviews for training, and 25,000 reviews for testing.\n",
    "<a href=\"https://imgur.com/FfdEBRz\"><img src=\"https://i.imgur.com/FfdEBRzm.png\" title=\"source: imgur.com\" align=\"right\"></a>\n",
    "- IMDB movie reviews dataset\n",
    "- http://ai.stanford.edu/~amaas/data/sentiment\n",
    "- https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "- Contains 25000 positive and 25000 negative reviews\n",
    "- Contains at most reviews per movie\n",
    "- At least 7 stars out of 10 $\\rightarrow$ positive (label = 1)\n",
    "- At most 4 stars out of 10 $\\rightarrow$ negative (label = 0)\n",
    "\n",
    "> **Here, we use PyTorch to train and test recurrent neural network to classify sentiments of reviews by inputting word embeddings to an LSTM layer which is connected to a fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3NKRSykDS0G"
   },
   "source": [
    "## <h2> <center>Dependencies</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "dqbcy5rGukws",
    "outputId": "1047b196-2c23-4089-8195-9aa50f9a4b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem import SnowballStemmer\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "radvvFiCupOC",
    "outputId": "cad17f0e-39a5-4b2a-9997-d2d22c43243f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>The movie uses random events of historical sig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29202</th>\n",
       "      <td>This film immediately catches the eye, with th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22041</th>\n",
       "      <td>This could well be the worst film I've ever se...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11942</th>\n",
       "      <td>I come from Bangladesh, and here, C.C.Costigan...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14771</th>\n",
       "      <td>The opening scene makes you feel like you're w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38772</th>\n",
       "      <td>I actually really like what I've seen of this ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>I have only see three episodes of Hack, starri...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "14390  The movie uses random events of historical sig...  negative\n",
       "29202  This film immediately catches the eye, with th...  positive\n",
       "22041  This could well be the worst film I've ever se...  negative\n",
       "11942  I come from Bangladesh, and here, C.C.Costigan...  negative\n",
       "14771  The opening scene makes you feel like you're w...  negative\n",
       "38772  I actually really like what I've seen of this ...  positive\n",
       "9640   I have only see three episodes of Hack, starri...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for importing data to colab\n",
    "from google.colab import drive \n",
    "drive.mount('/content/drive')\n",
    "\n",
    "movies = pd.read_csv('/content/drive/My Drive/Colab Notebooks/imdb_data.csv')\n",
    "movies.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3E69t4ODRke"
   },
   "source": [
    "## <h2> <center>Preprocessing</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "3z8MMjITupdS",
    "outputId": "87a8b6f6-d7ae-4b77-db74-a22ed3822e48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cateogrize positive and negative as 1 and 0 respectively\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "movies['sentiment'] = label_encoder.fit_transform(movies['sentiment'])\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a_SfAx2upkR"
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, custom = True, stem_words = True):\n",
    "    # Clean the text, with the option to remove stopwords and stem words.\n",
    "    \n",
    "    # Strip html\n",
    "    soup = BeautifulSoup(review, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    review_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    \n",
    "    # replace accents\n",
    "    review_text = unicodedata.normalize('NFKD', review_text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    review_text = re.sub(r\"[^A-Za-z0-9!?\\'\\`]\", \" \", review_text) # remove special characters\n",
    "    review_text = contractions.fix(review_text) # expand contractions\n",
    "    \n",
    "    review_text = review_text.lower()\n",
    "    words = review_text.split()\n",
    "    if custom:\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        stop_words.update(['movie', 'film', 'one', 'would', 'even', \n",
    "                           'movies', 'films', 'cinema',\n",
    "                           'character', 'show', \"'\", \"!\", 'like'])\n",
    "    else:\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    review_text = \" \".join(words)\n",
    "        \n",
    "    review_text = re.sub(r\"!\", \" ! \", review_text)\n",
    "    review_text = re.sub(r\"\\?\", \" ? \", review_text)\n",
    "    review_text = re.sub(r\"\\s{2,}\", \" \", review_text)\n",
    "    \n",
    "    if stem_words:\n",
    "        words = review_text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        review_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words, with each word as its own string\n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "ABBzydjp6cMI",
    "outputId": "92c63efe-373e-4079-cda2-23dc84a37d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 4.7MB/s \n",
      "\u001b[?25hCollecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 10.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81701 sha256=2b9d835661cf6bbfdd7cfd32221230f92ac06ea9791d5587317fa041ca8d13a9\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cVOZLyIupie"
   },
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].apply(review_to_wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYU_JNupDY8p"
   },
   "source": [
    "## <h2> <center>Features</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEuuJ2A0upgo"
   },
   "outputs": [],
   "source": [
    "all_text = ''\n",
    "all_text = '\\n'.join([review for review in movies['review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6FD_FWts_y0t",
    "outputId": "25b16ac9-e72b-48ce-9662-4210cf2555f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34683253"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UYNAqctrupbf",
    "outputId": "61fa71a8-3b06-4e84-e902-c2bf4ee13f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5716915"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split by new lines and spaces\n",
    "reviews_split = all_text.split('\\n')\n",
    "all_text = ' '.join(reviews_split)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CVUaM6wupZJ"
   },
   "outputs": [],
   "source": [
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key = counts.get, reverse = True)\n",
    "word_id = {word: i for i, word in enumerate(vocab, 1)} # dictionary to words to ints\n",
    "\n",
    "review_ids = []\n",
    "for review in reviews_split:\n",
    "    review_ids.append([word_id[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-ByAvYWz_Rhp",
    "outputId": "86865f43-09a5-4ee3-b0e0-2eb0be710314"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_ids) # list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T9W9VvMRAhFq",
    "outputId": "60a661bc-44d3-45ff-9cfe-2f16e3fa3722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels = np.array(movies['sentiment'])\n",
    "len(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "bGSp7xmUupXg",
    "outputId": "e208ccaf-7531-4d63-a645-d78e4c48a078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  74476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((word_id))) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d227QiIiupVN",
    "outputId": "91e64ca2-487e-438f-d52f-d98e2cada6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 1437\n"
     ]
    }
   ],
   "source": [
    "# outlier review stats\n",
    "review_lens = Counter([len(x) for x in review_ids])\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgQIbJf6-VKS"
   },
   "source": [
    "> **Padding the sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETmNIB_3-MjJ"
   },
   "outputs": [],
   "source": [
    "def pad_features(review_ids, seq_length):\n",
    "    \"\"\" Return features of review_ints, where each review is \n",
    "        padded with 0's or truncated to the input seq_length.\n",
    "    \"\"\" \n",
    "\n",
    "    features = np.zeros((len(review_ids), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, truncate the review to seq_length\n",
    "    for i, row in enumerate(review_ids):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "KaHFIeI--Mp5",
    "outputId": "97ba6c08-26c6-401c-ff86-d0a017644632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [  111   115  3344    34    39    75 12267   201  3344   463]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [ 1882  3518   765  5685  1005  2345   202  1285   361    22]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [  184   413   300   415   139 10272    39     3   502   335]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 200\n",
    "\n",
    "features = pad_features(review_ids, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(review_ids), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l--BvnlMChJJ"
   },
   "source": [
    "## <h2> <center>Split the data</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "w2eIVSU5CekL",
    "outputId": "fc830020-17f3-4512-b3f2-29fb85d338f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(40000, 200) \n",
      "Validation set: \t(5000, 200) \n",
      "Test set: \t\t(5000, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdOV2O0WCr_K"
   },
   "source": [
    "> **Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IJzYh2LCehf"
   },
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-y2sMJFtCee8"
   },
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "4Df7enBiCebV",
    "outputId": "c2ea95fc-0a67-492b-9a46-2189e979aff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 200])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ..., 14634,  4722,   461],\n",
      "        [    0,     0,     0,  ...,  9765,  8528,   184],\n",
      "        [    0,     0,     0,  ..., 15671,   157,   287],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,   529,    87,     1],\n",
      "        [    0,     0,     0,  ...,    23,  4271,   238],\n",
      "        [    0,     0,     0,  ...,   975, 15445,  1623]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDL0UeboDIpE"
   },
   "source": [
    "## <h2> <center>RNN with PyTorch</center></h2>\n",
    "---\n",
    "# Sentiment Network with PyTorch\n",
    "\n",
    "The layers are as follows:\n",
    "1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n",
    "2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n",
    "3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
    "4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u_VSfzeQ-Mn2",
    "outputId": "e74d3fe7-5472-4c67-c898-1f9fd42e601a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OormiUsFDAzw"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0yhabNmEdY6"
   },
   "source": [
    "> **Instantiate the network**\n",
    "\n",
    "* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n",
    "* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n",
    "* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n",
    "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "BR7wT78FDA3P",
    "outputId": "dcc5fa19-bfd2-4089-dbf0-b8a178b3f153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(74477, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(word_id)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LP-SRowxEtgB"
   },
   "source": [
    "> **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qHUQ1V5DAx5"
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr= 1e-2\n",
    "\n",
    "criterion = nn.BCELoss() # binary classification\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "colab_type": "code",
    "id": "f_R0-4KjDAvM",
    "outputId": "a8777048-a772-441f-f3b6-99c498420aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.426109... Val Loss: 0.546336\n",
      "Epoch: 1/4... Step: 200... Loss: 0.370746... Val Loss: 0.405227\n",
      "Epoch: 1/4... Step: 300... Loss: 0.407962... Val Loss: 0.368187\n",
      "Epoch: 1/4... Step: 400... Loss: 0.429482... Val Loss: 0.336268\n",
      "Epoch: 1/4... Step: 500... Loss: 0.284186... Val Loss: 0.391333\n",
      "Epoch: 1/4... Step: 600... Loss: 0.382884... Val Loss: 0.346030\n",
      "Epoch: 1/4... Step: 700... Loss: 0.387173... Val Loss: 0.329737\n",
      "Epoch: 1/4... Step: 800... Loss: 0.359384... Val Loss: 0.326282\n",
      "Epoch: 2/4... Step: 900... Loss: 0.124210... Val Loss: 0.313134\n",
      "Epoch: 2/4... Step: 1000... Loss: 0.149514... Val Loss: 0.310041\n",
      "Epoch: 2/4... Step: 1100... Loss: 0.397794... Val Loss: 0.336854\n",
      "Epoch: 2/4... Step: 1200... Loss: 0.233860... Val Loss: 0.317808\n",
      "Epoch: 2/4... Step: 1300... Loss: 0.293050... Val Loss: 0.317159\n",
      "Epoch: 2/4... Step: 1400... Loss: 0.185084... Val Loss: 0.312834\n",
      "Epoch: 2/4... Step: 1500... Loss: 0.270117... Val Loss: 0.320038\n",
      "Epoch: 2/4... Step: 1600... Loss: 0.516689... Val Loss: 0.371944\n",
      "Epoch: 3/4... Step: 1700... Loss: 0.239949... Val Loss: 0.348201\n",
      "Epoch: 3/4... Step: 1800... Loss: 0.223722... Val Loss: 0.365001\n",
      "Epoch: 3/4... Step: 1900... Loss: 0.147633... Val Loss: 0.377308\n",
      "Epoch: 3/4... Step: 2000... Loss: 0.239776... Val Loss: 0.322240\n",
      "Epoch: 3/4... Step: 2100... Loss: 0.246914... Val Loss: 0.307504\n",
      "Epoch: 3/4... Step: 2200... Loss: 0.389992... Val Loss: 0.346564\n",
      "Epoch: 3/4... Step: 2300... Loss: 0.262844... Val Loss: 0.312884\n",
      "Epoch: 3/4... Step: 2400... Loss: 0.274883... Val Loss: 0.421391\n",
      "Epoch: 4/4... Step: 2500... Loss: 0.206981... Val Loss: 0.325183\n",
      "Epoch: 4/4... Step: 2600... Loss: 0.194859... Val Loss: 0.338903\n",
      "Epoch: 4/4... Step: 2700... Loss: 0.272930... Val Loss: 0.334428\n",
      "Epoch: 4/4... Step: 2800... Loss: 0.358271... Val Loss: 0.365325\n",
      "Epoch: 4/4... Step: 2900... Loss: 0.176508... Val Loss: 0.336287\n",
      "Epoch: 4/4... Step: 3000... Loss: 0.177836... Val Loss: 0.420910\n",
      "Epoch: 4/4... Step: 3100... Loss: 0.325324... Val Loss: 0.341791\n",
      "Epoch: 4/4... Step: 3200... Loss: 0.159782... Val Loss: 0.351082\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qbiNs7krFEL4"
   },
   "source": [
    "\n",
    "> **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFDrlpQJ-Ml3"
   },
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "KHmfIVgV-MgQ",
    "outputId": "0e2d6a55-11e5-46fa-e217-b6606d2402f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.339\n",
      "Test accuracy: 86.040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -- stats! -- #\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiD5Y7cjFN9h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "RNN_predictions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
